\documentclass[12pt,a4paper]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{url}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{float}
\usepackage{changepage}
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{placeins}
\usepackage{amssymb}
\usepackage{appendix}

\usepackage[most]{tcolorbox}
\tcbset{
  colback=blue!3!white,
  colframe=blue!70!black,
  left=2mm,
  right=2mm,
  top=1mm,
  bottom=1mm,
  before skip=10pt,
  after skip=10pt,
  sharp corners,
  borderline west={2pt}{0pt}{blue!70!black}
}

\newenvironment{notebox}[1][Note]{%
  \begin{tcolorbox}[title=\textbf{#1}]
}{%
  \end{tcolorbox}
}

\geometry{a4paper, margin=1in}
\pagestyle{fancy}
\fancyhf{}
\rhead{Projet Statistiques et Probabilités I}
\lhead{Analyse des logs HDFS}
\rfoot{\thepage}

\title{Statistiques et Probabilités I \\ Analyse statistique et probabiliste des logs HDFS pour la détection d'anomalies}
\author{Nom Prénom}
\date{\today}

\begin{document}

\thispagestyle{empty}
\begin{center}

% --- Logo Section ---
\vspace*{1cm}
\begin{minipage}{\textwidth}
  \centering
  \includegraphics[height=1.8cm]{university_logo.png}
\end{minipage}

\vspace{2.5cm}

{\LARGE \textbf{Rapport de Projet}} \\[1.5cm]

{\Huge \textbf{Statistiques et Probabilités I}} \\[1.2cm]
{\LARGE \textbf{Analyse statistique et probabiliste }} \\[0.3cm]
{\LARGE \textbf{des logs HDFS pour la détection d'anomalies}} \\[3cm]

{\large \textbf{Réalisé par:}} \\[0.3cm]

\begin{center}
\rule{0.8\textwidth}{0.5pt} \\[0.2cm]
\begin{tabular}{c@{\hspace{1.5cm}}c}
  \large\textbf{Aya ABID} & \large\textbf{Farah AMHALI} \\
\end{tabular} \\[0.2cm]
\large\textbf{Aya SQUALLI HOUSSAINI} \\[0.2cm]
\rule{0.8\textwidth}{0.5pt}
\end{center}
\\[0.8cm]

% --- Encadrant ---
{\large \textbf{Encadré par:}} \\[0.2cm]
{\large \textbf{Pr. Ikram CHAIRI}} \\[0.8cm]

\vspace{2cm}
% --- Dates ---
{\large \textbf{\today}} \\[0.5cm]

\end{center}
\newpage


\tableofcontents
\newpage

\section{Introduction}
\label{sec:intro}

Les logs système sont une source essentielle pour la supervision, le diagnostic et la détection d'incidents. En cybersécurité, l'analyse de logs permet de repérer des comportements atypiques pouvant correspondre à des défaillances ou à des actions malveillantes. Le système de fichiers distribué Hadoop (HDFS) génère des journaux détaillés qui capturent l'activité du cluster, offrant ainsi une riche source de données pour l'analyse statistique.

Ce projet se concentre sur l'analyse statistique des logs HDFS avec les objectifs suivants:
\begin{itemize}
    \item Nettoyer et structurer les données de logs HDFS
    \item Construire des variables quantitatives pertinentes à partir de traces d'événements
    \item Réaliser une analyse univariée et multivariée
    \item Effectuer un ajustement linéaire simple
    \item Tracer des distributions et discuter leur compatibilité avec des lois de probabilité classiques
    \item Optionnellement, effectuer des tests statistiques ou un modèle de prédiction simple
\end{itemize}

\section{Contexte et Données}
\label{sec:contexte}

\subsection{Jeu de données HDFS}
Les logs HDFS utilisés dans ce projet proviennent d'un environnement de production Hadoop. Chaque enregistrement correspond à une opération sur un bloc de données, identifié par son \texttt{BlockId}. Les données sont étiquetées comme normales (Normal) ou anormales (Anomaly), permettant ainsi une analyse supervisée.

\subsection{Variables étudiées}
À partir des logs bruts, nous avons extrait les variables suivantes:
\begin{itemize}
    \item \texttt{seq\_len}: Longueur de la séquence d'événements par bloc
    \item \texttt{unique\_events}: Nombre d'événements distincts par bloc
    \item \texttt{total\_count}: Nombre total d'occurrences d'événements
    \item Variables de fréquence pour les événements les plus courants
    \item \texttt{entropy}: Entropie de la distribution des événements (optionnel)
\end{itemize}

\subsection{Structure des données}
Les logs sont regroupés par \texttt{BlockId}, chaque bloc correspondant à une trace d'événements et étant associé à un label binaire. Cette structure permet une analyse à deux niveaux: au niveau du bloc et au niveau des événements individuels.

\section{Méthodologie}
\label{sec:methodologie}

\subsection{Prétraitement des données}
Le prétraitement comprend les étapes suivantes:
\begin{enumerate}
    \item Chargement et fusion des fichiers de logs
    \item Nettoyage des données (valeurs manquantes, doublons)
    \item Transformation des variables catégorielles
    \item Création de nouvelles variables dérivées
    \item Normalisation des variables quantitatives
\end{enumerate}

\subsection{Analyse univariée}
Pour chaque variable quantitative, nous réalisons:
\begin{itemize}
    \item Calcul des statistiques descriptives (moyenne, médiane, écart-type, quantiles)
    \item Visualisation via histogrammes et boîtes à moustaches
    \item Test de normalité (Shapiro-Wilk, QQ-plots)
    \item Calcul des coefficients d'asymétrie et d'aplatissement
\end{itemize}

\subsection{Analyse multivariée}
L'analyse multivariée comprend:
\begin{itemize}
    \item Matrice de corrélation (Pearson et Spearman)
    \item Analyse en composantes principales (ACP) pour la réduction de dimension
    \item Nuages de points avec régression linéaire
    \item Comparaison des distributions par label
\end{itemize}

\subsection{Modélisation probabiliste}
Nous testons l'adéquation des données avec plusieurs lois de probabilité:
\begin{itemize}
    \item \textbf{Distribution de Bernoulli/Binomiale} pour les variables binaires
    \item \textbf{Distribution de Poisson} pour les variables de comptage
    \item \textbf{Distribution Normale} après transformation logarithmique si nécessaire
    \item \textbf{Distribution Multinomiale} pour les variables catégorielles multiples
\end{itemize}

\section{Résultats et Analyse}
\label{sec:resultats}

\subsection{Statistiques descriptives}

\begin{table}[h]
\centering
\caption{Statistiques descriptives des variables principales}
\label{tab:descriptives}
\begin{tabular}{lccccc}
\toprule
Variable & Moyenne & Médiane & Écart-type & Skewness & Kurtosis \\
\midrule
\texttt{seq\_len} & 145.3 & 132 & 45.6 & 1.2 & 4.3 \\
\texttt{unique\_events} & 28.7 & 25 & 12.4 & 0.8 & 3.1 \\
\texttt{total\_count} & 150.1 & 138 & 48.2 & 1.1 & 4.0 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Distribution des variables}

\begin{figure}[h]
  \centering
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{hist_seq_len.png}
    \caption{Distribution de \texttt{seq\_len}}
    \label{fig:hist_seq_len}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{hist_unique_events.png}
    \caption{Distribution de \texttt{unique\_events}}
    \label{fig:hist_unique_events}
  \end{subfigure}
  \caption{Histogrammes des variables principales}
  \label{fig:histogrammes}
\end{figure}

\subsection{Corrélations entre variables}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{correlation_matrix.png}
    \caption{Matrice de corrélation entre variables}
    \label{fig:correlation}
\end{figure}

\subsection{Test d'adéquation aux lois de probabilité}

\subsubsection{Test avec la loi de Poisson}
Pour la variable \texttt{unique\_events}, nous testons l'adéquation avec une loi de Poisson:

\begin{table}[h]
\centering
\caption{Test d'adéquation à la loi de Poisson}
\label{tab:poisson_test}
\begin{tabular}{lcc}
\toprule
Paramètre & Valeur estimée & p-valeur \\
\midrule
$\lambda$ & 28.7 & 0.043 \\
\bottomrule
\end{tabular}
\end{table}

\begin{notebox}
Le test du chi-deux indique que la distribution de \texttt{unique\_events} n'est pas parfaitement ajustée par une loi de Poisson (p-valeur < 0.05), mais l'approximation reste raisonnable pour certaines analyses.
\end{notebox}

\subsubsection{Transformation logarithmique et normalité}
Pour les variables fortement asymétriques comme \texttt{seq\_len}, une transformation logarithmique améliore l'adéquation à la distribution normale:

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{qqplot_log_seq_len.png}
    \caption{QQ-plot de \texttt{log(seq\_len)}}
    \label{fig:qqplot}
\end{figure}

\section{Discussion}
\label{sec:discussion}

\subsection{Interprétation des résultats}
Les analyses réalisées révèlent plusieurs caractéristiques importantes des logs HDFS:
\begin{itemize}
    \item La longueur des séquences présente une asymétrie positive, suggérant la présence de blocs avec des traces particulièrement longues
    \item Le nombre d'événements uniques suit approximativement une loi de Poisson, ce qui correspond à un processus de comptage
    \item Les fortes corrélations entre certaines variables suggèrent des relations structurelles dans le comportement du système
    \item La transformation logarithmique permet d'approcher la normalité pour certaines variables, facilitant ainsi l'application de tests paramétriques
\end{itemize}

\subsection{Limitations et perspectives}
\begin{itemize}
    \item \textbf{Limitations}: La taille de l'échantillon peut limiter la généralisation des résultats. De plus, les labels "Anomaly" peuvent couvrir différents types d'anomalies qui mériteraient une analyse plus fine.
    \item \textbf{Perspectives}: Une analyse plus approfondie pourrait inclure des modèles de séries temporelles pour capturer l'évolution temporelle des logs, ou des méthodes d'apprentissage automatique pour la prédiction d'anomalies.
\end{itemize}

\section{Conclusion}
\label{sec:conclusion}

Ce projet a permis de réaliser une analyse statistique complète des logs HDFS, mettant en évidence les distributions caractéristiques des variables d'intérêt et leur adéquation avec des lois de probabilité classiques. Les principales contributions sont:

\begin{itemize}
    \item Une méthodologie systématique pour le prétraitement et l'analyse des logs système
    \item Une caractérisation statistique détaillée des variables dérivées des logs HDFS
    \item Des tests d'adéquation aux lois de probabilité qui éclairent la nature stochastique des phénomènes observés
    \item Des visualisations qui facilitent l'interprétation des résultats
\end{itemize}

Les résultats obtenus fournissent une base solide pour des analyses plus avancées, telles que la détection automatique d'anomalies ou l'optimisation des performances du système HDFS.

\section*{Références}

\begin{thebibliography}{9}

\bibitem{hadoop}
Apache Hadoop Documentation. \emph{HDFS Architecture Guide}. 
\url{https://hadoop.apache.org/docs/}

\bibitem{loganalysis}
He, P., Zhu, J., He, S., Li, J., \& Lyu, M. R. (2016). 
\emph{An Evaluation Study on Log Parsing and Its Use in Log Mining}. 
IEEE/IFIP International Conference on Dependable Systems and Networks (DSN).

\bibitem{statmethods}
Field, A., Miles, J., \& Field, Z. (2012). 
\emph{Discovering Statistics Using R}. Sage Publications.

\bibitem{probmodels}
Casella, G., \& Berger, R. L. (2002). 
\emph{Statistical Inference}. Duxbury Press.

\bibitem{hdfslogs}
Xu, W., Huang, L., Fox, A., Patterson, D., \& Jordan, M. I. (2009). 
\emph{Detecting Large-Scale System Problems by Mining Console Logs}. 
SOSP '09.

\end{thebibliography}

\newpage 
\appendix
\label{app:appendix}
\section{Annexe: Code et Données}

Le code source complet de l'analyse ainsi que les données utilisées sont disponibles sur:

\noindent\href{https://github.com/votrenom/projet-hdfs-stats}{\texttt{https://github.com/votrenom/projet-hdfs-stats}}

\vspace{0.5em}
Le dépôt contient:
\begin{itemize}
  \item Scripts Python pour le prétraitement des données
  \ Notebooks Jupyter pour l'analyse statistique
  \item Scripts R pour les tests statistiques avancés
  \item Les visualisations générées
  \item Documentation détaillée de la méthodologie
\end{itemize}

\section{Annexe: Tables supplémentaires}

\begin{table}[h]
\centering
\caption{Résultats des tests de normalité}
\label{tab:normality_tests}
\begin{tabular}{lccc}
\toprule
Variable & Test Shapiro-Wilk (p-value) & Test Anderson-Darling & Conclusion \\
\midrule
\texttt{seq\_len} & 0.001 & 15.3 & Non normal \\
\texttt{log(seq\_len)} & 0.125 & 0.8 & Normal \\
\texttt{unique\_events} & 0.023 & 3.2 & Non normal \\
\bottomrule
\end{tabular}
\end{table}

\end{document}